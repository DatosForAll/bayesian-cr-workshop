---
title: "Crash course on Bayesian statistics and MCMC algorithms"
author: "The team"
date: "last updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, "slides-theme.css"]
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      slideNumberFormat: ''
      titleSlideClass: [center, middle]
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(comment = "")
library(tidyverse)
theme_set(theme_light(14))
update_geom_defaults("point", list(size = 2)) 
library(here)
library(nimble)
```

class: center, middle
background-image: url(img/amazing-thomas-bayes-illustration.jpg)
background-size: cover


---
# Bayes' theorem

.pull-left[
.title-font[]

* A theorem about conditional probabilities.

* $\Pr(B \mid A) = \displaystyle{\frac{ \Pr(A \mid B) \; \Pr(B)}{\Pr(A)}}$

]

--

.pull-right[
.title-font[]

.center[
![](img/bayes_neon.jpeg)
]

.tiny[Bayes' theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: Wikipedia]

]

---
# Bayes' theorem

+ I always forget what the letters mean. 

--

+ Might be easier to remember when written like this:

$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$
--

+ The "hypothesis" is typically something unobserved or unknown. It's what you want to learn about using the data. 

--

+ For regression models, the "hypothesis" is a parameter (intercept, slopes or error terms).

--

+ Bayes theorem tells you the probability of the hypothesis given the data.

---
# What is doing science after all?

How plausible is some hypothesis given the data?

$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$

---
# Why is Bayesian statistics not the default?

--

+ Due to practical problems of implementing the Bayesian approach, and some wars of male statisticians's egos, little advance was made for over two centuries.

--

+ Recent advances in computational power coupled with the development of new methodology have led to a great increase in the application of Bayesian methods within the last two decades.


---
# Frequentist versus Bayesian	

--

+ Typical stats problems involve estimating parameter $\theta$ with available data.

--

+ The frequentist approach (**maximum likelihood estimation** – MLE) assumes that the parameters are fixed, but have unknown values to be estimated.

--

+ Classical estimates generally provide a point estimate of the parameter of interest.

--

+ The Bayesian approach assumes that the parameters are not fixed but have some fixed  unknown distribution - a distribution for the parameter.

---
# What is the Bayesian approach?	

--

+ The approach is based upon the idea that the experimenter begins with some prior beliefs about the system.

--

+ And then updates these beliefs on the basis of observed data.

--

+ This updating procedure is based upon the Bayes' Theorem:

$$\Pr(A \mid B) = \frac{\Pr(B \mid A) \; \Pr(A)}{\Pr(B)}$$

---
# What is the Bayesian approach?	

--

+ Schematically if $A = \theta$ and $B = \text{data}$, then

--

+ The Bayes' theorem

$$\Pr(A \mid B) = \frac{\Pr(B \mid A) \; \Pr(A)}{\Pr(B)}$$

--

+ Translates into:

$$\Pr(\theta \mid \text{data}) = \frac{\Pr(\text{data} \mid \theta) \; \Pr(\theta)}{\Pr(\text{data})}$$

---
# Bayes' theorem	

$${\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \; \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}$$

--

+ $\color{red}{\text{Posterior distribution}}$: Represents what you know after having seen the data. The basis for inference, a distribution, possibly multivariate if more than one parameter. 

--

+ $\color{blue}{\text{Likelihood}}$: We know that quantity, same as in the MLE approach.

--

+ $\color{green}{\text{Prior distribution}}$: Represents what you know before seeing the data. The source of much discussion about the Bayesian approach.

--

+ $\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}$ is a $N$-dimensional integral if $\theta = \theta_1, \ldots, \theta_N$. 

--

+ Difficult if not impossible to calculate. This is one of the reasons why we need simulation (MCMC) methods.


---
# Brute force approach via numerical integration

--

+ Say we release $n$ animals at the beginning of the winter, out of which $y$ survive, and we'd like to estimate winter survival. 
```{r}
y <- 19 # nb of success
n <- 57 # nb of attempts
```

--

+ Likelihood $\text{Binomial}(57, \theta)$

--

+ Prior $\text{Beta}(a = 1, b = 1)$

---
# Beta prior

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}
a <- 1; b <- 1; p <- seq(0,1,.002); prior <- dbeta(p,a,b)
dfprior <- data.frame(p = p, prior = prior) 
dfprior %>%
  ggplot() + 
  geom_line(aes(x = p, y = prior), size = 1.5)
#plot(p, dbeta(p,a,b), type='l', lwd=3)
```
]

---
# Apply Bayes theorem

+ Likelihood times the prior: $\Pr(\text{data} \mid \theta) \; \Pr(\theta)$
```{r}
numerator <- function(p) dbinom(y,n,p) * dbeta(p,a,b)
```

+ Averaged likelihood: $\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \; \Pr(\theta) d\theta}$
```{r}
denominator <- integrate(numerator,0,1)$value
```

---
# Posterior via numerical integration

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}
numerical_posterior <- data.frame(p = p, posterior = numerator(p)/denominator) 
numerical_posterior %>%
  ggplot() + 
  geom_line(aes(x = p, y = posterior), 
            size = 1.5, 
            col = "darkgreen", 
            alpha = 0.5)
```
]

---
# Superimpose explicit posterior

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}
explicit_posterior <- dbeta(p, y + a, n - y + b)
dfexpposterior <- data.frame(p = p, explicit_posterior = explicit_posterior)
ggplot() + 
  geom_line(data = numerical_posterior, 
            aes(x = p, y = posterior), 
            size = 1.5, 
            col = "darkgreen",
            alpha = 0.5) + 
  geom_line(data = dfexpposterior, 
            aes(x = p, y = explicit_posterior),
            size = 1.5, 
            col = "darkred", 
            linetype = "dashed")
```
]

---
# And the prior

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}
ggplot() + 
  geom_line(data = numerical_posterior, 
            aes(x = p, y = posterior), 
            size = 1.5, 
            col = "darkgreen", 
            alpha = 0.5) + 
  geom_line(data = dfexpposterior, 
            aes(x = p, y = explicit_posterior),
            col = "darkred", 
            size = 1.5, 
            linetype = "dashed") + 
  geom_line(data = dfprior,
            aes(x = p, y = prior),
            col = "darkblue",
            size = 1.5)
```
]

---
# What if multiple parameters, like in a simple linear regression?

+ Example of a linear regression with parameters $\alpha$, $\beta$ and $\sigma$ to be estimated. 

--

+ Bayes' theorem says:

$$ P(\alpha, \beta, \sigma \mid \text{data}) = \frac{ P(\text{data} \mid \alpha, \beta, \sigma) \, P(\alpha, \beta, \sigma)}{\iiint \, P(\text{data} \mid \alpha, \beta, \sigma) \, P(\alpha, \beta, \sigma) \,d\alpha \,d\beta \,d\sigma} $$

--

+ Do we really wish to calculate a 3D integral?

---
# Bayesian computation

--

+ In the early 1990s, statisticians rediscovered work from the 1950's in physics.

```{r, fig.align = 'center', echo = FALSE, out.width = "600cm"}
knitr::include_graphics(here::here("slides/img","metropolis.png"))
```

--

+ Use stochastic simulation to draw samples from posterior distributions.

--

+ Avoid explicit calculation of integrals in Bayes formula.

--

+ Instead, approx. posterior w/ some precision by drawing large samples.

--

* Markov chain Monte Carlo (MCMC) gives a boost to Bayesian statistics!

---


```{r, fig.align = 'center', echo = FALSE, out.width = "700cm"}
knitr::include_graphics(here::here("slides/img","maniac.png"))
```

---
# Why are MCMC methods so useful?

+ MCMC are stochastic algorithms to produce sequence of dependent random numbers from a Markov chain.

+ Converge to equilibrium (aka stationary) distribution.

+ Equilibrium distribution is the desired posterior distribution!

+ Several ways of constructing these chains: e.g., Metropolis-Hastings, Gibbs sampler.

+ How to implement them in practice?!

---
# The Metropolis algorithm

+ Let's go back to animal survival estimation.

+ We illustrate sampling from the posterior distribution. 

+ We write functions in `R` for the likelihood, the prior and the posterior.

---

```{r}
# survival data, 19 "success" out of 57 "attempts"
survived <- 19
released <- 57

# log-likelihood function
loglikelihood <- function(x, p){
  dbinom(x = x, size = released, prob = p, log = TRUE)
}

# prior density
logprior <- function(p){
  dunif(x = p, min = 0, max = 1, log = TRUE)
}

# posterior density function (log scale)
posterior <- function(x, p){
  loglikelihood(x, p) + logprior(p) # - log(Pr(data))
}
```

---
# Metropolis algorithm

--

1. We start at any possible value of the parameter to be estimated. 

--

2. To decide where to visit next, we propose to move away from the current value of the parameter. We add to this current value some random value from say a normal distribution with some variance. We call this the **candidate** location.

--

3. We compute the ratio of the probabilities at the candidate and current locations $R = posterior(candidate)/posterior(current)$. This is where the magic of MCMC happens, in that $\Pr(data)$ (the denominator of the Bayes theorem) cancels out when we compute $R$. 

--

4. We spin a continuous spinner that lands anywhere from 0 to 1 –- call the random spin $X$. If $X$ is smaller than $R$, we move to the candidate location, otherwise we remain at the current location.

--

5. We repeat 2-4 a number of times called **steps** (many steps).

---

```{r}
# propose candidate value
move <- function(x, away = .2){ 
  logitx <- log(x / (1 - x))
  logit_candidate <- logitx + rnorm(1, 0, away)
  candidate <- plogis(logit_candidate)
  return(candidate)
}

# set up the scene
steps <- 100
theta.post <- rep(NA, steps)
set.seed(1234)

# pick starting value (step 1)
inits <- 0.5
theta.post[1] <- inits
```

---

```{r}
for (t in 2:steps){ # repeat steps 2-4 (step 5)
  
  # propose candidate value for prob of success (step 2)
  theta_star <- move(theta.post[t-1])
  
  # calculate ratio R (step 3)
  pstar <- posterior(survived, p = theta_star)  
  pprev <- posterior(survived, p = theta.post[t-1])
  logR <- pstar - pprev
  R <- exp(logR)
  
  # decide to accept candidate value or to keep current value (step 4)
  accept <- rbinom(1, 1, prob = min(R, 1))
  theta.post[t] <- ifelse(accept == 1, theta_star, theta.post[t-1])
}
```

---

Starting at the value $0.5$ and running the algorithm for $100$ iterations.

```{r}
head(theta.post)
tail(theta.post)
```

---

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}
df <- data.frame(x = 1:steps, y = theta.post)
df %>%
  ggplot() +
  geom_line(aes(x = x, y = y), size = 1.5, color = "darkgreen") + 
  labs(x = "iterations", y = "values from posterior distribution") + 
  ylim(0.1, 0.6)
```
]

---

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}

# pick starting value (step 1)
inits <- 0.2
theta.post2 <- rep(NA, steps)
theta.post2[1] <- inits

for (t in 2:steps){ # repeat steps 2-4 (step 5)
  # propose candidate value for prob of success (step 2)
  theta_star <- move(theta.post2[t-1])
  # calculate ratio R (step 3)
  pstar <- posterior(survived, p = theta_star)  
  pprev <- posterior(survived, p = theta.post[t-1])
  logR <- pstar - pprev
  R <- exp(logR)
  
  # decide to accept candidate value or to keep current value (step 4)
  accept <- rbinom(1, 1, prob = min(R, 1))
  theta.post2[t] <- ifelse(accept == 1, theta_star, theta.post2[t-1])
}

df2 <- data.frame(x = 1:steps, y = theta.post2)
  ggplot() +
  geom_line(data = df, aes(x = x, y = y), size = 1.5) + 
  geom_line(data = df2, aes(x = x, y = y), size = 1.5, color = "darkblue") + 
  labs(x = "iterations", y = "values from posterior distribution") + 
  ylim(0.1, 0.6)
```
]


---

.center.nogap[
```{r, echo = FALSE, fig.width = 7.5, fig.asp = 0.618, dev = "svg"}
# set up the scene
steps <- 5000
theta.post <- rep(NA, steps)
set.seed(1234)

# pick starting value (step 1)
inits <- 0.5
theta.post[1] <- inits

for (t in 2:steps){ # repeat steps 2-4 (step 5)
  
  # propose candidate value for prob of success (step 2)
  theta_star <- move(theta.post[t-1])
  
  # calculate ratio R (step 3)
  pstar <- posterior(survived, p = theta_star)  
  pprev <- posterior(survived, p = theta.post[t-1])
  logR <- pstar - pprev
  R <- exp(logR)
  
  # decide to accept candidate value or to keep current value (step 4)
  accept <- rbinom(1, 1, prob = min(R, 1))
  theta.post[t] <- ifelse(accept == 1, theta_star, theta.post[t-1])
}

df <- data.frame(x = 1:steps, y = theta.post)
df %>%
  ggplot() +
  geom_line(aes(x = x, y = y), size = 1, color = "darkgreen") + 
  labs(x = "iterations", y = "values from posterior distribution") + 
  ylim(0.1, 0.6) + 
  geom_hline(aes(yintercept = mean(theta.post)), 
             color = "darkblue",
             size = 1.2) + 
  geom_hline(aes(yintercept = 19/57), 
             color = "darkred",
             size = 1.2)
  

#abline(h = mean(theta.post), col = "blue", lwd = 2)
#text(3700, 0.57, "posterior mean", col = "blue", adj = c(-.1, -.1))
#abline(h = 19/57, col = "red", lwd = 2)
#text(3700, 0.55, "max lik estimate", col = "red", adj = c(-.1, -.1))
```
]

---
# Animating MCMC - 1D example

.center[
![](img/112546886-56862f00-8dba-11eb-81a0-465434672bdd.gif)]

Code here: <https://gist.github.com/oliviergimenez/5ee33af9c8d947b72a39ed1764040bf3>


---
# Animating MCMC - 2D example

```{r, fig.align = 'center', echo = FALSE, out.width = "650cm"}
knitr::include_graphics(here::here("slides/img","create-gif.gif"))
```

Code here: <https://mbjoseph.github.io/posts/2018-12-25-animating-the-metropolis-algorithm/>

---
# The MCMC Interactive Gallery

.center[
![](img/galery.png)
]

Visit <https://chi-feng.github.io/mcmc-demo/>

---
# Assessing convergence

--

+ MCMC algorithms can be used to construct a Markov chain with a given stationary distribution (set to be the posterior distribution).

--

+ For the MCMC algorithm, the posterior distribution is only needed to be known up to proportionality. 

--

+ Once the stationary distribution is reached, we can regard the realisations of the chain as a (dependent) sample from the posterior distribution (and obtain Monte Carlo estimates).

--

+ We consider some important implementation issues.

---
# Mixing and autocorrelation

.center[
![](img/mixing.png)
]

???

+ The movement around the parameter space is often referred to as **mixing**.

+ Traceplots of for small and big moves provide (relatively) high correlations (known as autocorrelations) between successive observations of the Markov chain.

+ Strongly correlated observations require large sample sizes and therefore longer simulations.

+ Autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in the given sample values.

+ ACF plots provide the autocorrelation between successively sampled values separated by $k$ iterations, referred to as lag, (i.e. $\text{cor}(\theta_t, \theta_{t+k})$) for increasing values of $k$.

---
# How do good chains behave? 

--

+ Converge to same target distribution: We need to think of the time required for convergence (realisations of the Markov chain have to be discarded before this is achieved).

--

+ Once there, explore efficiently: The post-convergence sample size required for suitable numerical summaries.

--

+ Therefore, we are looking to determine how long it takes for the Markov chain to converge to the stationary distribution.

--

+ In practice, we must discard observations from the start of the chain and just use observations from the chain once it has converged.

--

+ The initial observations that we discard are referred to as the **burn-in**.

--

+ The simplest method to determine the length of the burn-in period is to look at trace plots.

---
## Burn-in (if simulations cheap, be conservative)

.center[
![](img/burnin.png)
]

---
# Effective sample size `n.eff`

--

* How long of a chain is needed to produce stable estimates ?

--

* Most MCMC chains are strongly autocorrelated.

--

* Successive steps are near each other, and are not independent. 

--

* The effective sample size (`n.eff`) measures chain length while taking into account the autocorrelation of the chain.
    * `n.eff` is less than the number of MCMC iterations.
    * Check the `n.eff` of every parameter of interest.
    * Check the `n.eff` of any interesting parameter combinations.

--

* We need $\text{n.eff} \geq 100$ independent steps. 

---
# Potential scale reduction factor

--

+ Gelman-Rubin statistic $\hat{R}$

--

+ Measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability. Asks the question is there a chain effect? Very much alike the $F$ test in an ANOVA. 

--

+ Values near $1$ indicates likely convergence, a value of $\leq 1.1$ is considered acceptable.

--

+ Necessary condition, not sufficient; In other words, these diagnostics cannot tell you that you have converged for sure, only that you have not. 

---
# To sum up

--

+ Run multiple chains from arbitrary starting places (initial values).

--

+ Assume convergence when all chains reach same regime

--

+ Discard initial burn-in phase.

--

+ Proceed with posterior inference. 

--

+ Use traceplot, effective sample size and $\hat{R}$.

---
# What if you have issues of convergence?

--

+ Increase burn-in, sample more.

--

+	Use more informative priors.

--

+ Pick better initial values (good guess).

--

+ Reparameterize: 
     + Standardize covariates.
     + Non-centering: $\alpha \sim N(0,\sigma)$ becomes $\alpha = z \sigma$ with $z \sim N(0,1)$.

--

+	Something wrong with your model? 
     + Start with a simpler model (remove complexities). 
     + Use simulations. 

--

+ Change your sampler. More in the Nimble section. 


---
# Further reading

+ ref 1
+ ref 2
+ ref 3

---
# To-do list

+ Smooth everything
+ Time the whole class to make sure we're below 1 hour
+ Add something on Monte Carlo estimates, on Markov chains?